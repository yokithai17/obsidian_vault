---
tags:
  - Математика/ML
up: "[[Анализ Данных]]"
---

_Precision_ и _recall_ не зависят, в отличие от _accuracy_, от соотношения классов и потому применимы в условиях несбалансированных выборок. Часто в реальной практике стоит задача найти оптимальный (для заказчика) баланс между этими двумя метриками. Понятно что чем выше точность и полнота, тем лучше. Но в реальной жизни максимальная точность и полнота не достижимы одновременно и приходится искать некий баланс. Поэтому, хотелось бы иметь некую метрику которая объединяла бы в себе информацию о точности и полноте нашего алгоритма. В этом случае нам будет проще принимать решение о том какую реализацию запускать в производство (у кого больше тот и круче). Именно такой метрикой является _F-мера_.

F-мера представляет собой [гармоническое среднее](https://ru.wikipedia.org/wiki/%D0%A1%D1%80%D0%B5%D0%B4%D0%BD%D0%B5%D0%B5_%D0%B3%D0%B0%D1%80%D0%BC%D0%BE%D0%BD%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5) между точностью и полнотой. Она стремится к нулю, если точность или полнота стремится к нулю.

$$F=\dfrac{2 \times precision \times recall}{precision + recall}$$

Данная формула придает одинаковый вес точности и полноте, поэтому F-мера будет падать одинаково при уменьшении и точности и полноты. Возможно рассчитать _F-меру_ придав различный вес точности и полноте, если вы осознанно отдаете приоритет одной из этих метрик при разработке алгоритма:

$$F_{\beta}=\dfrac{(1+\beta^{2}) \times precision \times recall}{(\beta^{2} \times precision) + recall}$$где $\beta$ принимает значения в диапазоне $0 \lt \beta \lt 1$ если вы хотите отдать приоритет точности, а при $\beta \gt$ приоритет отдается полноте. При $\beta=1$ формула сводится к предыдущей и вы получаете сбалансированную $F$-меру (также ее называют $F_{1}$).

_F-мера_ достигает максимума при максимальной полноте и точности, и близка к нулю, если один из аргументов близок к нулю.

_F-мера_ является хорошим кандидатом на формальную метрику оценки качества классификатора. Она сводит к одному числу две других основополагающих метрики: точность и полноту. Имея "F-меру" гораздо проще ответить на вопрос: "поменялся алгоритм в лучшую сторону или нет?"

```python
 # код для подсчета метрики F-mera:
 # Пример классификатора, способного проводить различие между всего лишь двумя**
 # классами, "пятерка" и "не пятерка" из набора рукописных цифр MNIST**
 import numpy as np
 from sklearn.datasets import fetch_openml
 from sklearn.model_selection import cross_val_predict
 from sklearn.linear_model import SGDClassifier
 from sklearn.metrics import f1_score
 mnist = fetch_openml('mnist_784', version=1)
 X, y = mnist["data"], mnist["target"]
 y = y.astype(np.uint8)
 X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]
 y_train_5 = (y_train == 5) # True для всех пятерок, False для в сех остальных цифр. Задача опознать пятерки
 y_test_5 = (y_test == 5)
 sgd_clf = SGDClassifier(random_state=42) # классификатор на основе метода стохастического градиентного спуска (Stochastic Gradient Descent SGD)
 sgd_clf.fit(X_train, y_train_5) # обучаем классификатор распознавать пятерки на целом обучающем наборе
 y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)
 print(f1_score(y_train_5, y_train_pred))
 
 # 0.7325171197343846
```